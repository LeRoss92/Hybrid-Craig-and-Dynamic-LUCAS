{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d714f4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T23:41:04.726991Z",
     "iopub.status.busy": "2026-02-03T23:41:04.726726Z",
     "iopub.status.idle": "2026-02-03T23:41:11.331743Z",
     "shell.execute_reply": "2026-02-03T23:41:11.330864Z"
    },
    "papermill": {
     "duration": 6.609905,
     "end_time": "2026-02-03T23:41:11.332623",
     "exception": false,
     "start_time": "2026-02-03T23:41:04.722718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# CONFIG: Adjust this to speed up or slow down\n",
    "MAX_WORKERS = 50  # Try 10, 20, 30, 40 - higher = faster but may hit rate limits\n",
    "chunk_size = 1000\n",
    "\n",
    "# Specify pixel size and tile size at the top of the cell\n",
    "PIXEL_SIZE = 10   # size of each pixel in meters\n",
    "example_TILE_SIZE = 9     # number of pixels on one side of the tile\n",
    "TILE_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5d6506",
   "metadata": {
    "papermill": {
     "duration": 0.001787,
     "end_time": "2026-02-03T23:41:11.337146",
     "exception": false,
     "start_time": "2026-02-03T23:41:11.335359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Parallel download function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c5c7b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T23:41:11.344508Z",
     "iopub.status.busy": "2026-02-03T23:41:11.344273Z",
     "iopub.status.idle": "2026-02-03T23:41:11.356735Z",
     "shell.execute_reply": "2026-02-03T23:41:11.356156Z"
    },
    "papermill": {
     "duration": 0.015761,
     "end_time": "2026-02-03T23:41:11.357268",
     "exception": false,
     "start_time": "2026-02-03T23:41:11.341507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def extract_single_site(site_idx, lat, lon, collection, unique_years, patch_size, n_dims):\n",
    "    \"\"\"Extract embeddings for one site - runs in parallel.\"\"\"\n",
    "    embeddings = np.full((n_dims, len(unique_years), patch_size, patch_size), np.nan, dtype=np.float32)\n",
    "    \n",
    "    try:\n",
    "        point = ee.Geometry.Point([lon, lat])\n",
    "        intersecting_tiles = collection.filterBounds(point)\n",
    "        total_tiles = intersecting_tiles.size().getInfo()\n",
    "        \n",
    "        for tile_idx in range(total_tiles):\n",
    "            try:\n",
    "                img = ee.Image(intersecting_tiles.toList(1, tile_idx).get(0))\n",
    "                time_start = img.get('system:time_start').getInfo()\n",
    "                tile_year = datetime.datetime.fromtimestamp(time_start/1000).year\n",
    "                \n",
    "                if tile_year in unique_years:\n",
    "                    year_idx = unique_years.index(tile_year)\n",
    "                    half_size = patch_size // 2\n",
    "                    \n",
    "                    points = []\n",
    "                    for row in range(patch_size):\n",
    "                        for col in range(patch_size):\n",
    "                            lat_offset = (row - half_size) * PIXEL_SIZE / 111000\n",
    "                            lon_offset = (col - half_size) * PIXEL_SIZE / (111000 * np.cos(np.radians(lat)))\n",
    "                            points.append(ee.Geometry.Point([lon + lon_offset, lat + lat_offset]))\n",
    "                    \n",
    "                    samples = img.sample(\n",
    "                        region=ee.Geometry.MultiPoint(points),\n",
    "                        scale=PIXEL_SIZE,\n",
    "                        numPixels=patch_size*patch_size\n",
    "                    ).getInfo()\n",
    "                    \n",
    "                    if samples['features']:\n",
    "                        for idx, feature in enumerate(samples['features']):\n",
    "                            if idx < patch_size*patch_size:\n",
    "                                row, col = idx // patch_size, idx % patch_size\n",
    "                                props = feature['properties']\n",
    "                                for i in range(n_dims):\n",
    "                                    val = props.get(f\"A{i:02d}\", None)\n",
    "                                    if val is not None:\n",
    "                                        embeddings[i, year_idx, row, col] = val\n",
    "            except:\n",
    "                pass\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return site_idx, embeddings\n",
    "\n",
    "\n",
    "def extract_satellite_embeddings_parallel(coordinates, years=None, patch_size=example_TILE_SIZE):\n",
    "    \"\"\"Parallel download using MAX_WORKERS from config.\n",
    "    \n",
    "    Args:\n",
    "        coordinates: List or array of [lat, lon] coordinates.\n",
    "        years: List of years to extract embeddings for. If None, all years in the collection are used.\n",
    "        patch_size: Size of patch for embedding extraction.\n",
    "    \"\"\"\n",
    "    coords = np.array(coordinates)\n",
    "    if coords.ndim == 1:\n",
    "        coords = coords.reshape(1, -1)\n",
    "    \n",
    "    collection = ee.ImageCollection(\"GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL\")\n",
    "    years_list = collection.aggregate_array('system:time_start').getInfo()\n",
    "    all_years = sorted(list(set(\n",
    "        datetime.datetime.fromtimestamp(ts/1000).year for ts in years_list\n",
    "    )))\n",
    "    \n",
    "    if years is None:\n",
    "        unique_years = all_years\n",
    "    else:\n",
    "        unique_years = [y for y in years if y in all_years]\n",
    "        if len(unique_years) < len(years):\n",
    "            missing = set(years) - set(unique_years)\n",
    "            print(f\"Warning: The following requested years are not available in the collection: {missing}\")\n",
    "\n",
    "    n_sites, n_years, n_dims = coords.shape[0], len(unique_years), 64\n",
    "    embeddings = np.full((n_sites, n_dims, n_years, patch_size, patch_size), np.nan, dtype=np.float32)\n",
    "    \n",
    "    total_points = coords.shape[0]\n",
    "    completed = 0\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        future_to_site = {\n",
    "            executor.submit(extract_single_site, site_idx, lat, lon, collection, unique_years, patch_size, n_dims): site_idx\n",
    "            for site_idx, (lat, lon) in enumerate(coords)\n",
    "        }\n",
    "        \n",
    "        for future in as_completed(future_to_site):\n",
    "            site_idx, site_embeddings = future.result()\n",
    "            embeddings[site_idx] = site_embeddings\n",
    "            completed += 1\n",
    "            percent = 100.0 * completed / total_points\n",
    "            print(f\"Progress: {percent:6.3f}%\", end='\\r')\n",
    "    \n",
    "    return embeddings, coords, unique_years\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c2c6b",
   "metadata": {
    "papermill": {
     "duration": 0.001759,
     "end_time": "2026-02-03T23:41:11.360878",
     "exception": false,
     "start_time": "2026-02-03T23:41:11.359119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Initialize connection to gee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48339fdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T23:41:11.365551Z",
     "iopub.status.busy": "2026-02-03T23:41:11.365402Z",
     "iopub.status.idle": "2026-02-03T23:41:11.368235Z",
     "shell.execute_reply": "2026-02-03T23:41:11.367615Z"
    },
    "papermill": {
     "duration": 0.005937,
     "end_time": "2026-02-03T23:41:11.368641",
     "exception": false,
     "start_time": "2026-02-03T23:41:11.362704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "save_path = \"3_AlphaEarth\"\n",
    "if not os.path.exists(f\"{save_path}/0_2018gps_2017_2018embeddings.pkl\"):\n",
    "    # Authenticate and initialize the Earth Engine client library if not already initialized\n",
    "    try:\n",
    "        ee.Initialize()\n",
    "    except Exception as e:\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf1098e",
   "metadata": {
    "papermill": {
     "duration": 0.001797,
     "end_time": "2026-02-03T23:41:11.372273",
     "exception": false,
     "start_time": "2026-02-03T23:41:11.370476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Chunk into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22cea20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T23:41:11.376515Z",
     "iopub.status.busy": "2026-02-03T23:41:11.376385Z",
     "iopub.status.idle": "2026-02-03T23:41:12.684280Z",
     "shell.execute_reply": "2026-02-03T23:41:12.683357Z"
    },
    "papermill": {
     "duration": 1.311239,
     "end_time": "2026-02-03T23:41:12.685273",
     "exception": false,
     "start_time": "2026-02-03T23:41:11.374034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test 100 sites first - adjust MAX_WORKERS above to optimize speed\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "with open(\"2_preprocessed.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "lat = df['gps_lat_2018']\n",
    "long = df['gps_long_2018']   \n",
    "coordinates_18 = [[la, lo] for la, lo in zip(lat, long)]\n",
    "coordinate_18_packs = [coordinates_18[i:i+chunk_size] for i in range(0, len(coordinates_18), chunk_size)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a74dc9e",
   "metadata": {
    "papermill": {
     "duration": 0.001914,
     "end_time": "2026-02-03T23:41:12.689729",
     "exception": false,
     "start_time": "2026-02-03T23:41:12.687815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Download all batches (saves after each batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ead63e66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T23:41:12.694897Z",
     "iopub.status.busy": "2026-02-03T23:41:12.694648Z",
     "iopub.status.idle": "2026-02-03T23:41:12.700079Z",
     "shell.execute_reply": "2026-02-03T23:41:12.699440Z"
    },
    "papermill": {
     "duration": 0.009011,
     "end_time": "2026-02-03T23:41:12.700688",
     "exception": false,
     "start_time": "2026-02-03T23:41:12.691677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 exists, skipping\n",
      "Batch 1 exists, skipping\n",
      "Batch 2 exists, skipping\n",
      "Batch 3 exists, skipping\n",
      "Batch 4 exists, skipping\n",
      "Batch 5 exists, skipping\n",
      "Batch 6 exists, skipping\n",
      "Batch 7 exists, skipping\n",
      "Batch 8 exists, skipping\n",
      "Batch 9 exists, skipping\n",
      "Batch 10 exists, skipping\n",
      "Batch 11 exists, skipping\n",
      "Batch 12 exists, skipping\n",
      "Batch 13 exists, skipping\n",
      "Batch 14 exists, skipping\n",
      "Batch 15 exists, skipping\n",
      "Batch 16 exists, skipping\n",
      "Batch 17 exists, skipping\n",
      "Batch 18 exists, skipping\n",
      "Batch 19 exists, skipping\n",
      "Batch 20 exists, skipping\n",
      "Batch 21 exists, skipping\n",
      "Batch 22 exists, skipping\n",
      "Batch 23 exists, skipping\n",
      "Batch 24 exists, skipping\n",
      "Batch 25 exists, skipping\n",
      "Batch 26 exists, skipping\n",
      "Batch 27 exists, skipping\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Extract 2017 and 2018 for 2018 GPS coordinates\n",
    "for i in range(0, len(coordinate_18_packs)):\n",
    "    if os.path.exists(f\"{save_path}/{i}_2018gps_2017_2018embeddings.pkl\"):\n",
    "        print(f\"Batch {i} exists, skipping\")\n",
    "        continue\n",
    "    pack = coordinate_18_packs[i]\n",
    "    print(f\"\\nProcessing batch {i+1}/{len(coordinate_18_packs)} ({len(pack)} sites) with MAX_WORKERS={MAX_WORKERS}\")\n",
    "    embeddings, _, _ = extract_satellite_embeddings_parallel(pack, [2017, 2018], patch_size=TILE_SIZE)\n",
    "    with open(f\"{save_path}/{i}_2018gps_2017_2018embeddings.pkl\", \"wb\") as f:\n",
    "        pickle.dump(embeddings, f)\n",
    "    print(f\"\\nSaved batch {i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58c76e52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T23:41:12.705712Z",
     "iopub.status.busy": "2026-02-03T23:41:12.705574Z",
     "iopub.status.idle": "2026-02-03T23:41:13.320856Z",
     "shell.execute_reply": "2026-02-03T23:41:13.320282Z"
    },
    "papermill": {
     "duration": 0.619536,
     "end_time": "2026-02-03T23:41:13.322212",
     "exception": false,
     "start_time": "2026-02-03T23:41:12.702676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get 2017 and 2018 for 2018 GPS coordinates\n",
    "def get_multi_year(coordinates, year_idx):\n",
    "    AlphaEarth_values = np.zeros((len(coordinates), 64))\n",
    "    import math\n",
    "    num_packs = math.ceil(len(coordinates) / chunk_size)\n",
    "    idx = 0\n",
    "    for i in range(num_packs):\n",
    "        with open(f\"{save_path}/{i}_2018gps_2017_2018embeddings.pkl\", \"rb\") as f:\n",
    "            pack_values = pickle.load(f)\n",
    "        # Shape: (n_sites, n_dims, n_years, patch_size, patch_size)\n",
    "        pack_values = pack_values[:, :, year_idx, 0, 0]  # Extract specific year and center pixel\n",
    "        n = pack_values.shape[0]\n",
    "        AlphaEarth_values[idx:idx+n] = pack_values[:min(n, len(coordinates)-idx)]\n",
    "        idx += n\n",
    "    return AlphaEarth_values\n",
    "\n",
    "AE_18_2017 = get_multi_year(coordinates_18, 0)  # 2017 is first (sorted)\n",
    "AE_18_2018 = get_multi_year(coordinates_18, 1)  # 2018 is second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bf11732",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T23:41:13.328659Z",
     "iopub.status.busy": "2026-02-03T23:41:13.328463Z",
     "iopub.status.idle": "2026-02-03T23:41:13.346738Z",
     "shell.execute_reply": "2026-02-03T23:41:13.345834Z"
    },
    "papermill": {
     "duration": 0.022235,
     "end_time": "2026-02-03T23:41:13.347623",
     "exception": false,
     "start_time": "2026-02-03T23:41:13.325388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cols_18_2017 = [f\"AE{i:02d}_2018gps_2017\" for i in range(64)]\n",
    "cols_18_2018 = [f\"AE{i:02d}_2018gps_2018\" for i in range(64)]\n",
    "\n",
    "df_ae_18_2017 = pd.DataFrame(AE_18_2017, columns=cols_18_2017)\n",
    "df_ae_18_2018 = pd.DataFrame(AE_18_2018, columns=cols_18_2018)\n",
    "\n",
    "df = pd.concat([df, df_ae_18_2017, df_ae_18_2018], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f2c427a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T23:41:13.353245Z",
     "iopub.status.busy": "2026-02-03T23:41:13.353090Z",
     "iopub.status.idle": "2026-02-03T23:41:13.402231Z",
     "shell.execute_reply": "2026-02-03T23:41:13.401396Z"
    },
    "papermill": {
     "duration": 0.053133,
     "end_time": "2026-02-03T23:41:13.403050",
     "exception": false,
     "start_time": "2026-02-03T23:41:13.349917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_pickle(\"3_with_gee.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.013893,
   "end_time": "2026-02-03T23:41:13.820229",
   "environment_variables": {},
   "exception": null,
   "input_path": "3_add_gee.ipynb",
   "output_path": "3_add_gee.ipynb",
   "parameters": {},
   "start_time": "2026-02-03T23:41:02.806336",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}